import pandas as pd
import joblib
import warnings
from pathlib import Path
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score
from xgboost import XGBClassifier

warnings.filterwarnings("ignore")

# ====== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ======
CURRENT_DIR = Path(__file__).resolve().parent 
PROJECT_ROOT = CURRENT_DIR.parent.parent       
DATA_PATH = PROJECT_ROOT / "data" / "processed" / "ADHD_Merged_Data.csv"
MODEL_OUT = CURRENT_DIR / "adhd_xgb_model_optimized.joblib"

def optimize_adhd_model():
    print("ðŸš€ Starting Hyperparameter Tuning (Grid Search)...")
    print("â˜• Go make some coffee, this might take a few minutes...")

    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¯Ø§ØªØ§
    df = pd.read_csv(DATA_PATH)
    
    feature_cols = [
        "Conduct_Problems", "Total_Difficulties", "Emotional_Problems", 
        "Externalizing_Score", "Impact_Score", "Hyperactivity_Score", 
        "Internalizing_Score", "Peer_Problems", "Prosocial_Score",
        "APQ_Corporal_Punishment", "APQ_Inconsistent_Discipline", 
        "APQ_Involvement", "APQ_Other_Discipline", 
        "APQ_Poor_Monitoring", "APQ_Positive_Parenting",
        "Age", "Sex"
    ]
    target_col = "Class"
    
    X = df[feature_cols]
    y = df[target_col]

    # Ø§Ù„ØªÙ‚Ø³ÙŠÙ…
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆØ²Ù†
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()

    # ====== Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø´Ø¨ÙƒØ© (The Grid) ======
    # Ù‡Ù†Ø¬Ø±Ø¨ ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø¯ÙŠ
    param_grid = {
        'max_depth': [3, 4, 5, 6],
        'learning_rate': [0.01, 0.05, 0.1],
        'n_estimators': [100, 300, 500],
        'subsample': [0.7, 0.8, 0.9],
        'colsample_bytree': [0.6, 0.8],
        'gamma': [0, 0.1, 0.2] # Ù…Ø¹Ø§Ù…Ù„ Ù„Ù…Ù†Ø¹ Ø§Ù„Ù€ Overfitting
    }

    xgb = XGBClassifier(
        objective='binary:logistic',
        scale_pos_weight=scale_pos_weight,
        use_label_encoder=False,
        eval_metric='auc',
        n_jobs=-1,
        random_state=42
    )

    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£ÙØ¶Ù„ (Grid Search)
    grid_search = GridSearchCV(
        estimator=xgb,
        param_grid=param_grid,
        scoring='roc_auc', # Ø¨Ù†Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù€ AUC Ø£Ù‡Ù… Ù…Ù† Ø§Ù„Ù€ Accuracy
        cv=3,
        verbose=1,
        n_jobs=-1
    )

    grid_search.fit(X_train, y_train)

    print("\nâœ… Best Parameters Found:")
    print(grid_search.best_params_)

    # Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø­Ø³Ù†
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    y_prob = best_model.predict_proba(X_test)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_prob)

    print("\n" + "="*30)
    print(f"ðŸ† Optimized Results:")
    print(f"   - Accuracy: {acc*100:.2f}%")
    print(f"   - ROC AUC:  {roc_auc:.4f}")
    print("="*30)

    # Ø­ÙØ¸ Ø§Ù„Ø£ÙØ¶Ù„
    joblib.dump(best_model, MODEL_OUT)
    print(f"ðŸ’¾ Best Model Saved -> {MODEL_OUT}")

if __name__ == "__main__":
    optimize_adhd_model()