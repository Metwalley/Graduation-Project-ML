import pandas as pd
import joblib
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay
from xgboost import XGBClassifier, plot_importance
from pathlib import Path
import os

# ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø© Ù„ÙŠÙƒÙˆÙ† Ø§Ù„Ø®Ø±Ø¬ Ù†Ø¸ÙŠÙØ§Ù‹
warnings.filterwarnings("ignore")

CURRENT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = CURRENT_DIR.parent.parent
DATA_PATH = PROJECT_ROOT / "data" / "raw" / "Autism_Screening_Data_Combined.csv"
FILE_NAME = str(DATA_PATH)
print(f"ğŸ“‚ Loading data from: {FILE_NAME}")

MAX_AGE = 16  # Ø§Ù„ÙØ¦Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ© (Ø£Ø·ÙØ§Ù„)
FEATURES_OUT = "autism_features.joblib"  # Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ API
XGB_OUT = "autism_xgb_model.joblib"      # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
METRICS_OUT = "autism_xgb_metrics.joblib" # Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…

def train_autism_model():
    print("ğŸš€ Starting Autism Model Training...")

    # ====== 2. ØªØ­Ù…ÙŠÙ„ ÙˆØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¯Ø§ØªØ§ ======
    try:
        df = pd.read_csv(FILE_NAME)
    except FileNotFoundError:
        print(f"âŒ Error: The file '{FILE_NAME}' was not found.")
        return

    # ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª)
    df.columns = [c.strip() for c in df.columns]

    # ÙÙ„ØªØ±Ø© Ø§Ù„Ø¹Ù…Ø± (Ø§Ù„Ø£Ø·ÙØ§Ù„ ÙÙ‚Ø·)
    print(f"ğŸ“Š Filtering data for Age <= {MAX_AGE}...")
    df = df[df["Age"] <= MAX_AGE].copy()

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    feature_cols = ["A1", "A2", "A3", "A4", "A5", "A6", "A7", "A8", "A9", "A10", 
                    "Age", "Sex", "Jaundice", "Family_ASD"]
    target_col = "Class"

    # === Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ù‡Ù…: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ù‚Ø¨Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ (Robustness) ===
    # Ø¯Ù‡ Ø¨ÙŠØ­Ù…ÙŠ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ùˆ Ø§Ù„Ø¯Ø§ØªØ§ Ø¬Ø§ÙŠØ© ÙÙŠÙ‡Ø§ Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø­Ø±ÙˆÙ ÙƒØ¨ÙŠØ±Ø©
    text_cols = ["Sex", "Jaundice", "Family_ASD", "Class"]
    for col in text_cols:
        if col in df.columns:
            df[col] = df[col].astype(str).str.strip().str.lower()

    # Ø®Ø±Ø§Ø¦Ø· Ø§Ù„ØªØ­ÙˆÙŠÙ„ (Mappings)
    mappings = {
        "Sex": {"m": 1, "f": 0},
        "Jaundice": {"yes": 1, "no": 0},
        "Family_ASD": {"yes": 1, "no": 0},
        "Class": {"yes": 1, "no": 0} # Ù„Ø§Ø­Ø¸: Ø­ÙˆÙ„Ù†Ø§ ÙƒÙ„Ù‡ Ù„Ù€ small letters ÙÙˆÙ‚
    }

    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„
    for col, mp in mappings.items():
        if col in df.columns:
            df[col] = df[col].map(mp)

    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù†Ø¸Ø§ÙØ© Ø§Ù„Ø¯Ø§ØªØ§ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    df_final = df[feature_cols + [target_col]].dropna().copy()
    
    print(f"âœ… Data Ready: {len(df_final)} samples.")
    print(f"   - Class Distribution: {df_final[target_col].value_counts().to_dict()}")

    # ====== 3. Ø§Ù„ØªÙ‚Ø³ÙŠÙ… ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨ ======
    X = df_final[feature_cols]
    y = df_final[target_col]

    # Ø­ÙØ¸ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù€ Features Ø¹Ø´Ø§Ù† Ø§Ù„Ù€ API ÙŠØ·Ù„Ø¨Ù‡Ù… Ø¨Ù†ÙØ³ Ø§Ù„ØªØ±ØªÙŠØ¨
    joblib.dump(feature_cols, FEATURES_OUT)

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¯Ø§ØªØ§ (Stratified Ø¹Ø´Ø§Ù† Ø§Ù„ØªÙˆØ§Ø²Ù†)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆØ²Ù† Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ù… Ø§Ù„ØªÙˆØ§Ø²Ù† (Imbalance Handling)
    neg = (y_train == 0).sum()
    pos = (y_train == 1).sum()
    scale_pos_weight = neg / pos

    # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (XGBoost)
    xgb = XGBClassifier(
        n_estimators=500,        # Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø´Ø¬Ø§Ø± (ÙƒØ§ÙÙ Ø¬Ø¯Ø§Ù‹ Ù…Ø¹ Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ù…Ø¨ÙƒØ±)
        learning_rate=0.05,      # Ù…Ø¹Ø¯Ù„ ØªØ¹Ù„Ù… Ù‡Ø§Ø¯Ø¦ Ù„Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰
        max_depth=4,             # Ø¹Ù…Ù‚ Ù…ØªÙˆØ³Ø· Ù„Ù…Ù†Ø¹ Ø§Ù„Ù€ Overfitting
        subsample=0.8,
        colsample_bytree=0.8,
        use_label_encoder=False,
        eval_metric="auc",
        random_state=42,
        scale_pos_weight=scale_pos_weight,
        n_jobs=-1
    )

    # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    print("ğŸ”„ Training XGBoost Model...")
    xgb.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        early_stopping_rounds=50,
        verbose=False
    )

    # ====== 4. Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ======
    y_pred = xgb.predict(X_test)
    y_prob = xgb.predict_proba(X_test)[:, 1]

    acc = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_prob)

    print("\n" + "="*30)
    print(f"ğŸ† Final Results:")
    print(f"   - Accuracy: {acc*100:.2f}%")
    print(f"   - ROC AUC:  {roc_auc:.4f}")
    print("="*30)

    # Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    # ====== 5. Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„ØªØµØ¯ÙŠØ± ======
    # Ù„Ø§Ø­Ø¸: Ù…Ø´ Ø¨Ù†Ø­ÙØ¸ Scaler Ø®Ù„Ø§Øµ Ù„Ø£Ù† XGB Ù…Ø´ Ù…Ø­ØªØ§Ø¬Ù‡
    joblib.dump(xgb, XGB_OUT)
    
    metrics = {
        "accuracy": acc,
        "roc_auc": roc_auc,
        "report": classification_report(y_test, y_pred, output_dict=True)
    }
    joblib.dump(metrics, METRICS_OUT)

    print(f"ğŸ’¾ Model Saved Successfully -> {XGB_OUT}")
    print(f"ğŸ’¾ Features List Saved -> {FEATURES_OUT}")

    # (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) Ø±Ø³Ù… Ø§Ù„Ù€ Feature Importance
    plt.figure(figsize=(10, 6))
    plot_importance(xgb, max_num_features=10, importance_type="gain", title="Top 10 Features (Gain)")
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    train_autism_model()